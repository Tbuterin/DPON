# MODIFIED a2c_ppo_acktr/storage.py: added class TrajStorage for in-order storage of sampled trajectories. Search KEY: 240825tra

@20240829
# MKDIR DPO under DPO4VLM/VLM_PPO_ALF to save DPOTrainer codes
# COPY stepdpo_trainer into directory DPO
# MKFILE configs.py
      add functions: H4ArgumentParser, ModelArguments, DataArguments, RLArguments, DPOConfig, StepDPOConfig
# MODIFIED main_alf.py: add "import configs"
# COMMENTOUT main_alf.py args=get_args()  >>>注意，accelerate的config和程序传入的不是一个


@20240830
# MODIFIED a2c_ppo_acktr/storage.py: add function "to_dataset_dict" to class TrajStorage. KEY: 240830dic
# MODIFIED configs.py: 在parse_yaml_and_args中新增命令行参数解析格式




@20240909
# MODIFIED storage.py: start_traj函数添加了轨迹最大个数限制
